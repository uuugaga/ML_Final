{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T11:21:05.698242Z","iopub.status.busy":"2022-08-18T11:21:05.69756Z","iopub.status.idle":"2022-08-18T11:21:05.71509Z","shell.execute_reply":"2022-08-18T11:21:05.713469Z","shell.execute_reply.started":"2022-08-18T11:21:05.698186Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.impute import SimpleImputer\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from torch.autograd import Variable\n","import csv"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class mydataset(Dataset):\n","\n","    def __init__(self, train_or_test):\n","        # 讀檔\n","        submission = pd.read_csv(\"sample_submission.csv\")\n","        train = pd.read_csv(\"train.csv\")\n","        test = pd.read_csv(\"test.csv\")\n","\n","        # 把 id, product_code, failure等, training用不到的column去掉\n","        train_x = train.drop(columns=[\"id\",\"product_code\", \"failure\"])\n","        test_x = test.drop(columns=[\"id\",\"product_code\"])\n","\n","        # 把 failure從字串轉成數字\n","        train_y = train.iloc[:, -1]\n","\n","        # 把 attribute的 \"material_{number}\" 轉成 \"{number}\"\n","        for i in range(len(train_x)):\n","            train_x.iat[i, 1] = train_x.iat[i, 1].split('_')[-1]\n","            train_x.iat[i, 2] = train_x.iat[i, 2].split('_')[-1]\n","\n","        for i in range(len(test_x)):\n","            test_x.iat[i, 1] = test_x.iat[i, 1].split('_')[-1]\n","            test_x.iat[i, 2] = test_x.iat[i, 2].split('_')[-1]\n","\n","\n","        # 因為資料有10%的空缺，空缺的部分用 median的方式填補\n","        imp = SimpleImputer(missing_values=np.nan, strategy='median')\n","        \n","        if(train_or_test == \"train\"):\n","            train_x = train_x.astype({'attribute_0':'float', 'attribute_1':'float', 'attribute_2':'float', 'attribute_3':'float', 'measurement_0':'float', 'measurement_1':'float', 'measurement_2':'float'})\n","            train_imp = imp.fit(train_x)\n","            self.datas = train_imp.transform(train_x)\n","        if(train_or_test == \"test\"):\n","            test_x = test_x.astype({'attribute_0':'float', 'attribute_1':'float', 'attribute_2':'float', 'attribute_3':'float', 'measurement_0':'float', 'measurement_1':'float', 'measurement_2':'float'})\n","            test_imp = imp.fit(test_x)\n","            self.datas = test_imp.transform(test_x)\n","   \n","        self.train_y = train_y.astype({'failure':'float'})\n","        \n","    def __len__(self):\n","        return len(self.datas)\n","        \n","    def __getitem__(self, idx):\n","        data = self.datas[idx]\n","        label = np.zeros(1, dtype=float)\n","        label[0] = self.train_y[idx]\n","        return data, label\n","\n","def train_data_loader():\n","    dataset = mydataset(\"train\")\n","    return DataLoader(dataset, batch_size=150, shuffle=True)\n","\n","def test_data_loader():\n","    dataset = mydataset(\"test\")\n","    return DataLoader(dataset, batch_size=128)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class NeuralNet(nn.Module):\n","    def __init__(self):\n","        super(NeuralNet, self).__init__()\n","        self.fc1 = nn.Linear(23, 32)        \n","        self.fc2 = nn.Linear(32, 64)\n","        self.fc3 = nn.Linear(64, 1)\n","        self.leaky_relu = nn.LeakyReLU(0.1)\n","        self.sigmoid = nn.Sigmoid()\n","    \n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.leaky_relu(out)\n","        out = self.fc2(out)\n","        out = self.leaky_relu(out)\n","        out = self.fc3(out)\n","        out = self.sigmoid(out)\n","        return out"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = torch.load('nn_model.pt', map_location=torch.device(device))\n","model = model.to(device)\n","model.eval()\n","\n","test_loader = test_data_loader()\n","\n","answer = np.array([])\n","for i, (data, _) in enumerate(test_loader):  \n","    data = Variable(data.float()).to(device)\n","    output = model(data).to(device)\n","    output = output.data.cpu().numpy().ravel()\n","    answer = np.append(answer, output)\n","    \n","submission = pd.read_csv(\"sample_submission.csv\")\n","submission[\"failure\"] = answer\n","submission.reset_index(drop=True).to_csv(\"submission.csv\", index=False)\n"]}],"metadata":{"kernelspec":{"display_name":"deeptest","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"d98369ac92fb2d1718ecfecfc4aa6e5e27b726d697ed68fd070f2caeb96d415e"}}},"nbformat":4,"nbformat_minor":4}
